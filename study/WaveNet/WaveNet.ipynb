{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn,utils \n",
    "import mxnet.ndarray as F\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WaveNet 구현을 위한 class를 정의\n",
    "+ 우선 integer값을 one-hot으로 변환하기 위한 class를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class One_Hot(nn.Block):\n",
    "    def __init__(self, depth):\n",
    "        super(One_Hot,self).__init__()\n",
    "        self.depth = depth\n",
    "        \n",
    "    def forward(self, X_in):\n",
    "        with X_in.context:\n",
    "            X_in = X_in\n",
    "            self.ones = nd.one_hot(nd.arange(self.depth), self.depth)\n",
    "            return self.ones[X_in,:]\n",
    "        \n",
    "    def __repr(self):\n",
    "        return self.__class__.__name__+\"({})\".format(self.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNet(nn.Block):\n",
    "    def __init__(self, mu=256,n_residue=32, n_skip= 512, dilation_depth=10, n_repeat=5):\n",
    "        # mu: audio quantization size\n",
    "        # n_residue: residue channels\n",
    "        # n_skip: skip channels\n",
    "        # dilation_depth & n_repeat: dilation layer setup\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.dilation_depth = dilation_depth\n",
    "        self.dilations = [2**i for i in range(dilation_depth)] * n_repeat      \n",
    "        with self.name_scope():\n",
    "            self.one_hot = One_Hot(mu)\n",
    "            self.from_input = nn.Conv1D(in_channels=mu, channels=n_residue, kernel_size=1)\n",
    "            self.conv_sigmoid = nn.Sequential()\n",
    "            self.conv_tanh = nn.Sequential()\n",
    "            self.skip_scale = nn.Sequential()\n",
    "            self.residue_scale = nn.Sequential()\n",
    "            for d in self.dilations:\n",
    "                self.conv_sigmoid.add(nn.Conv1D(in_channels=n_residue, channels=n_residue, kernel_size=2, dilation=d))\n",
    "                self.conv_tanh.add(nn.Conv1D(in_channels=n_residue, channels=n_residue, kernel_size=2, dilation=d))\n",
    "                self.skip_scale.add(nn.Conv1D(in_channels=n_residue, channels=n_skip, kernel_size=1, dilation=d))\n",
    "                self.residue_scale.add(nn.Conv1D(in_channels=n_residue, channels=n_residue, kernel_size=1, dilation=d))\n",
    "            self.conv_post_1 = nn.Conv1D(in_channels=n_skip, channels=n_skip, kernel_size=1)\n",
    "            self.conv_post_2 = nn.Conv1D(in_channels=n_skip, channels=mu, kernel_size=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        with x.context:\n",
    "            output = self.preprocess(x)\n",
    "            skip_connections = [] # save for generation purposes\n",
    "            for s, t, skip_scale, residue_scale in zip(self.conv_sigmoid, self.conv_tanh, self.skip_scale, self.residue_scale):\n",
    "                output, skip = self.residue_forward(output, s, t, skip_scale, residue_scale)\n",
    "                skip_connections.append(skip)\n",
    "            # sum up skip connections\n",
    "            output = sum([s[:,:,-output.shape[2]:] for s in skip_connections])\n",
    "            output = self.postprocess(output)\n",
    "        return output\n",
    "        \n",
    "    def preprocess(self, x):\n",
    "        output = F.transpose(self.one_hot(x).expand_dims(0),axes=(0,2,1))\n",
    "        output = self.from_input(output)\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, x):\n",
    "        output = F.relu(x)\n",
    "        output = self.conv_post_1(output)\n",
    "        output = F.relu(output)\n",
    "        output = self.conv_post_2(output)\n",
    "        output = nd.reshape(output,(output.shape[1],output.shape[2]))\n",
    "        output = F.transpose(output,axes=(1,0))\n",
    "        return output\n",
    "    \n",
    "    def residue_forward(self, x, conv_sigmoid, conv_tanh, skip_scale, residue_scale):\n",
    "        output = x\n",
    "        output_sigmoid, output_tanh = conv_sigmoid(output), conv_tanh(output)\n",
    "        output = F.sigmoid(output_sigmoid) * F.tanh(output_tanh)\n",
    "        skip = skip_scale(output)\n",
    "        output = residue_scale(output)\n",
    "        output = output + x[:,:,-output.shape[2]:]\n",
    "        return output, skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ stack of dilated casual convolution을 수행한 후에 residual_forward를 거친 후 최종적으로 Softmax를 거쳐서 우리가 원하는 class별 확률값을 산출한다.\n",
    "+ 다음으로 Softmax Distribution 적용을 위한 Encoder/Decoder 함수를 정의. 함수 내용은 수식을 코드로 바꾼거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mu_law(x, mu=256):\n",
    "    mu = mu-1\n",
    "    fx = np.sign(x) * np.log(1+mu*np.abs(x))/np.log(1+mu)\n",
    "    return np.floor((fx+1)/2*mu+0.5)/astype(np.long)\n",
    "\n",
    "def decode_mu_law(y, mu=256):\n",
    "    mu = mu-1\n",
    "    fx = (y-0.5)/mu*2-1\n",
    "    x = np.sign(fx)/mu*((1+mu)**np.abs(fx)-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 다음으로 네트워크 학습을 위해 네트워크 정의하고, parameter 및 Optimizer를 설정. \n",
    "+ Gluon에서 GPU를 사용하기 위해서는 별도의 context를 지정해주어야하기 떄문에 그 부분을 포함해서 코드를 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu(1)\n",
    "net = WaveNet(mu=128, n_residue=24, n_skip=128, dilation_depth=10, n_repeat=2)\n",
    "net.collect_params().initialize(ctx=ctx)\n",
    "#set optimizer\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer='adam', optimizer_params={'learning_rate:0.01'})\n",
    "g = data_generation(data, fs, mu=128, seq_size = 20000, ctx=ctx)\n",
    "batch_size = 64\n",
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ WAV데이터는 다음의 module를 통해 불러옴. \n",
    "+ 이 때 loading WAV가 stereo인 경우에는 2-dim형태이기 때문에 이를 mono 형태로 변환해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "fs, data = wavfile.read(os.getcwd()+'/parametric-2.wav')\n",
    "##stereo convert to mono\n",
    "data = data.sum(axis=1) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 해당 module을 통해 입력한 데이터를 Softmax Distribution을 수행하기 전에 전처리 과정필요\n",
    "+ 데이터는 -1 ~ 1 사이의 scale로 변환 시켜야함\n",
    "+ 그 이후 학습을 위한 데이터를 random으로 생성하기 위해 while문 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(data,framerate,seq_size = 6000, mu=256,ctx=ctx):\n",
    "    div = max(data.max(),abs(data.min()))\n",
    "    data = data/div\n",
    "    while True:\n",
    "        start = np.random.randint(0,data.shape[0]-seq_size)\n",
    "        ys = data[start:start+seq_size]\n",
    "        ys = encode_mu_law(ys,mu)\n",
    "        yield nd.array(ys[:seq_size],ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 그 다음 네트워크 학습\n",
    "+ 1000epoch를 학습하는 형태로 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_save = []\n",
    "max_epoch = 1000\n",
    "best_loss = sys.maxsize\n",
    "for epoch in range(max_epoch):\n",
    "    loss = 0.0\n",
    "    for _ in tqdm(range(batch_size)):\n",
    "        batch = next(g)\n",
    "        x = batch[:-1]\n",
    "        with autograd.record():\n",
    "            logits = net(x)\n",
    "            sz = logits.shape[0]\n",
    "            loss = loss + loss_fn(logits, batch[-sz:])\n",
    "            #loss = loss/batch_size\n",
    "        loss.backward()\n",
    "        trainer.step(1,ignore_stale_grad=True)\n",
    "    loss_save.append(nd.sum(loss).asscalar()/batch_size)\n",
    "\n",
    "    #save the best model\n",
    "    current_loss = nd.sum(loss).asscalar()/batch_size\n",
    "    if best_loss > current_loss:\n",
    "        print('epoch {}, loss {}'.format(epoch, nd.sum(loss).asscalar()/batch_size))\n",
    "        print(\"====save best model====\")\n",
    "        filename = '/home/skinet/work/research/WaveNet/models/best_perf_epoch_'+str(epoch)+\"_loss_\"+str(current_loss)\n",
    "        net.save_params(filename)\n",
    "        best_loss = current_loss\n",
    "    \n",
    "    # monitor progress\n",
    "    if epoch%100==0:        \n",
    "        batch = next(g)\n",
    "        logits = net(batch[:-1])\n",
    "        #_, i = logits.max(dim=1)\n",
    "        i = logits.argmax(1).asnumpy()\n",
    "        plt.figure(figsize=[16,4])\n",
    "        plt.plot(list(i))\n",
    "        plt.plot(list(batch.asnumpy())[sum(net.dilations)+1:],'.',ms=1)\n",
    "        plt.title('epoch {}'.format(epoch))\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 네트워크 학습을 수행한 후에 학습 결과를 바탕으로 하여 generation을 수행\n",
    "+ generation은 다음의 함수를 통해 수행. for-loop 형태로 되어 있어서 속도가 다소 느림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_slow(x,models,dilation_depth,n_repeat,ctx, n=100):\n",
    "    dilations = [2**i for i in range(dilation_depth)] * n_repeat \n",
    "    res = list(x.asnumpy())\n",
    "    for _ in tqdm(range(n)):\n",
    "        x = nd.array(res[-sum(dilations)-1:],ctx=ctx)\n",
    "        y = models(x)\n",
    "        res.append(y.argmax(1).asnumpy()[-1])\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
